{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m \u001b[39mimport\u001b[39;00m DiffusionPipeline, DPMSolverMultistepScheduler\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m repo_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstabilityai/stable-diffusion-2-base\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/miniconda3/lib/python3.9/site-packages/diffusers/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     is_flax_available,\n\u001b[1;32m      3\u001b[0m     is_inflect_available,\n\u001b[1;32m      4\u001b[0m     is_onnx_available,\n\u001b[1;32m      5\u001b[0m     is_scipy_available,\n\u001b[1;32m      6\u001b[0m     is_torch_available,\n\u001b[1;32m      7\u001b[0m     is_transformers_available,\n\u001b[1;32m      8\u001b[0m     is_unidecode_available,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     12\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.9.0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfiguration_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m ConfigMixin\n",
      "File \u001b[0;32m/usr/local/miniconda3/lib/python3.9/site-packages/diffusers/utils/__init__.py:46\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpil_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m PIL_INTERPOLATION\n\u001b[1;32m     45\u001b[0m \u001b[39mif\u001b[39;00m is_torch_available():\n\u001b[0;32m---> 46\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtesting_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m         floats_tensor,\n\u001b[1;32m     48\u001b[0m         load_hf_numpy,\n\u001b[1;32m     49\u001b[0m         load_image,\n\u001b[1;32m     50\u001b[0m         load_numpy,\n\u001b[1;32m     51\u001b[0m         parse_flag_from_env,\n\u001b[1;32m     52\u001b[0m         require_torch_gpu,\n\u001b[1;32m     53\u001b[0m         slow,\n\u001b[1;32m     54\u001b[0m         torch_all_close,\n\u001b[1;32m     55\u001b[0m         torch_device,\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     59\u001b[0m logger \u001b[39m=\u001b[39m get_logger(\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     62\u001b[0m hf_cache_home \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexpanduser(\n\u001b[1;32m     63\u001b[0m     os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mHF_HOME\u001b[39m\u001b[39m\"\u001b[39m, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mXDG_CACHE_HOME\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m~/.cache\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mhuggingface\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     64\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/miniconda3/lib/python3.9/site-packages/diffusers/utils/testing_utils.py:29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m is_torch_available():\n\u001b[1;32m     27\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     torch_device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m     is_torch_higher_equal_than_1_12 \u001b[39m=\u001b[39m version\u001b[39m.\u001b[39mparse(version\u001b[39m.\u001b[39mparse(torch\u001b[39m.\u001b[39m__version__)\u001b[39m.\u001b[39mbase_version) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m version\u001b[39m.\u001b[39mparse(\n\u001b[1;32m     31\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m1.12\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     34\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_higher_equal_than_1_12:\n\u001b[1;32m     35\u001b[0m         \u001b[39m# Some builds of torch 1.12 don't have the mps backend registered. See #892 for more details\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "import torch\n",
    "\n",
    "repo_id = \"stabilityai/stable-diffusion-2-base\"\n",
    "pipe = DiffusionPipeline.from_pretrained(repo_id, torch_dtype=torch.float16, revision=\"fp16\")\n",
    "\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"High quality photo of an astronaut riding a horse in space\"\n",
    "image = pipe(prompt, num_inference_steps=25).images[0]\n",
    "image.save(\"astronaut.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
